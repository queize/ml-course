{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAmUD1eZHryf"
   },
   "source": [
    "# **Word vectors**\n",
    "\n",
    "\n",
    "In the previous exercise we observed that colors that we think of as similar are 'closer' to each other in RGB vector space. Is it possible to create a vector space for all English words that has this same 'closer in space is closer in meaning' property?\n",
    "\n",
    "The answer is yes! Luckily, you don't need to create those vectors from scratch. Many researchers have made downloadable databases of pre-trained vectors. One such project is [Stanford's Global Vectors for Word Representation (GloVe)](https://nlp.stanford.edu/projects/glove/). \n",
    "\n",
    "These $300$-dimensional vectors are included with $\\texttt{spaCy}$, and they're the vectors we'll be using in this exercise.\n",
    "\n",
    "![cosine similarity: picture](https://d33wubrfki0l68.cloudfront.net/d2742976a92aa4d6c39f19c747ec5f56ed1cec30/3803f/images/guide-to-word-vectors-with-gensim-and-keras_files/word2vec-king-queen-vectors.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n",
      "\n",
      "X.shape : (4, 4)\n",
      "\n",
      "add x :\n",
      "[[ 0  2  4  6]\n",
      " [ 8 10 12 14]\n",
      " [16 18 20 22]\n",
      " [24 26 28 30]]\n",
      "\n",
      "X*X^T  :\n",
      "[[ 56  62  68  74]\n",
      " [152 174 196 218]\n",
      " [248 286 324 362]\n",
      " [344 398 452 506]]\n",
      "\n",
      "mean over cols :\n",
      "[ 1.5  5.5  9.5 13.5]\n",
      "\n",
      "cumsum of cols :\n",
      "[[ 0  1  2  3]\n",
      " [ 4  6  8 10]\n",
      " [12 15 18 21]\n",
      " [24 28 32 36]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# numpy world\n",
    "\n",
    "x = np.arange(16).reshape(4,4)\n",
    "\n",
    "print(\"X :\\n%s\\n\" % x)\n",
    "print(\"X.shape : %s\\n\" % (x.shape,))\n",
    "print(\"add x :\\n%s\\n\" % (x + x))\n",
    "print(\"X*X^T  :\\n%s\\n\" % np.matmul(x,x.T))\n",
    "print(\"mean over cols :\\n%s\\n\" % (x.mean(axis=-1)))\n",
    "print(\"cumsum of cols :\\n%s\\n\" % (np.cumsum(x,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymHr8XZIHsML"
   },
   "outputs": [],
   "source": [
    "# The following will download the language model.\n",
    "# Resart the runtime (Runtime -> Restart runtime) after running this cell\n",
    "# (and don't run it for the second time).\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pb7yqHuGJ6e5"
   },
   "source": [
    "Let's load the model now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "A-8rsSkSBU8C"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNf5FAkm3Ljj"
   },
   "source": [
    "## **Word vectors: the first glance**\n",
    "\n",
    "You can see the vector of any word in $\\texttt{spaCy}$'s vocabulary using the $\\texttt{vector}$ attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vx-IzWxQAgNN",
    "outputId": "4b556f39-edfa-4bd2-8ec8-7d342fd82009"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A 300-dimensional vector\n",
    "len(nlp('dog').vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U8UP3QrxKZPG",
    "outputId": "5a4089cd-17d2-44c1-e98a-07ce4e505312"
   },
   "outputs": [],
   "source": [
    "# nlp('dog').vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHWCqKcl55TY"
   },
   "source": [
    "## **Cosine similarity**\n",
    "\n",
    "**Cosine similarity** is a common way of assessing similarity between words in NLP. It is essentially defined as the cosine of the angle between the vectors representing the words of interest.\n",
    "\n",
    "Recall that the angle $\\phi$ between two non-zero vectors $u$ and $v$ can be computed as follows:\n",
    "\n",
    "$cos(\\phi) = \\frac{(u,v)}{||u||\\cdot||v||}$\n",
    "\n",
    "![](https://miro.medium.com/max/1394/1*_Bf9goaALQrS_0XkBozEiQ.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoi6FvPgMWid"
   },
   "source": [
    "Define a function computing cosine similarity between two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WpJS01dmvGbe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine(v1, v2):\n",
    "    if np.linalg.norm(v1)*np.linalg.norm(v2) > 0:\n",
    "        return np.dot(v1, v2) / (np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEwtAXJRMc-s"
   },
   "source": [
    "Test your function by computing similarities of some random pairs of words, e.g. $dog$ and $puppy$ vs. $dog$ and $kitten$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RBooDbGvYOG",
    "outputId": "ead58779-a59c-4a40-986e-b924e0077331"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8107667"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(nlp('dog').vector, nlp('puppy').vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Vrw3AvECJKm",
    "outputId": "4fb2eacc-a44d-4a58-84b2-6c452c3d3553"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.651503"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(nlp('dog').vector, nlp('kitten').vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEIsbCETySyh",
    "outputId": "41326c88-d404-47c4-b3c5-92fde8b34662"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20769283"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(nlp('dog').vector, nlp('coffee').vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46489927"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(nlp('barcelona').vector, nlp('spain').vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgHDwfx8Mu66"
   },
   "source": [
    "## **Loading the text**\n",
    "\n",
    "Let's load the full text of *Alice in Wonderland*. It will serve us as a corpus of English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "am8NoIl2zMXi"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Alice in Wonderland\n",
    "response = requests.get('https://www.gutenberg.org/files/11/11-0.txt')\n",
    "\n",
    "# If you prefer Dracula, load this instead:\n",
    "#response = requests.get('https://www.gutenberg.org/cache/epub/345/pg345.txt')\n",
    "\n",
    "# Extracting separate words from the text\n",
    "doc = nlp(response.text)\n",
    "tokens = list(set([w.text for w in doc if w.is_alpha]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAwABf4nNNR3"
   },
   "source": [
    "Check out the content of $\\texttt{tokens}$ now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "d4B4FRR6NRzx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3137"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GfkThRpNUKL"
   },
   "source": [
    "Define a function that takes a word and lists the $n$ most similar words in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "KT_h-7n50kia"
   },
   "outputs": [],
   "source": [
    "def spacy_closest(tokens, new_vec, n=10):\n",
    "    return sorted(tokens,\n",
    "                  key=lambda x: cosine(new_vec, nlp(x).vector),\n",
    "                  reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTLEiz9UNjrO"
   },
   "source": [
    "Try to find words similar to some random words, e.g. $good$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1JL2VrF0ltD",
    "outputId": "1f2fa7bc-0ec1-483c-a3e0-ba5b3182fd4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'great',\n",
       " 'bad',\n",
       " 'excellent',\n",
       " 'nice',\n",
       " 'better',\n",
       " 'wonderful',\n",
       " 'pleasant',\n",
       " 'wise',\n",
       " 'happy']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_closest(tokens, nlp('good').vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLphWVCeOEDM",
    "outputId": "59a487e5-dc6e-4538-be19-6a9ee93cb19c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tea',\n",
       " 'toffee',\n",
       " 'drink',\n",
       " 'wine',\n",
       " 'kettle',\n",
       " 'custard',\n",
       " 'bread',\n",
       " 'meal',\n",
       " 'milk',\n",
       " 'bottle']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_closest(tokens, nlp('coffee').vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBZhjqSgNqNd"
   },
   "source": [
    "You can also get creative and search for combinations of words. For example, what is similar to $king - man + woman$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NKI4SrhMN-EV",
    "outputId": "b6a9418b-c548-442d-e7d1-4f788c33d144"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['king',\n",
       " 'throne',\n",
       " 'courtiers',\n",
       " 'royal',\n",
       " 'crown',\n",
       " 'King',\n",
       " 'conquest',\n",
       " 'Queen',\n",
       " 'father',\n",
       " 'usurpation']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vec = nlp('king').vector - nlp('man').vector + nlp('woman').vector\n",
    "spacy_closest(tokens, new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5p4rzE8ChHs",
    "outputId": "9ea9b593-4fe7-4459-e1a8-0a1c0d32b9b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['king',\n",
       " 'man',\n",
       " 'girl',\n",
       " 'boy',\n",
       " 'woman',\n",
       " 'father',\n",
       " 'person',\n",
       " 'friend',\n",
       " 'child',\n",
       " 'someone']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vec = nlp('king').vector - nlp('queen').vector + nlp('girl').vector\n",
    "spacy_closest(tokens, new_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpD73pj8OGGt"
   },
   "source": [
    "## **Sentence vectors**\n",
    "\n",
    "We can also construct a vector representation for the whole sentence. For example, we can define it as an *average* of the   vectors representing the words in it.\n",
    "\n",
    "Let's take a random sentence *My favorite food is strawberry ice cream* and construct its vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "p5xr_3MkEPeM"
   },
   "outputs": [],
   "source": [
    "sent = nlp('My favorite food is strawberry ice cream.')\n",
    "\n",
    "sentv = 0\n",
    "for w in sent:\n",
    "    sentv += w.vector\n",
    "sentv /= len(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMf_OllyOvfX"
   },
   "source": [
    "Let's also extract sentences (as opposed to individual words) from our corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "jazUz0WvDsa3"
   },
   "outputs": [],
   "source": [
    "sents = list(doc.sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzDdce7xO7QZ"
   },
   "source": [
    "Define a function that takes a random sentence and lists $n$ most similar sentences from our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "uQ7pQe8xD1x0"
   },
   "outputs": [],
   "source": [
    "def spacy_closest_sent(sentences, input_vec, n=10):\n",
    "    return sorted(sentences,\n",
    "                  key=lambda x: cosine(np.mean([w.vector for w in x], axis=0), input_vec),\n",
    "                  reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6m06T18PDQ8"
   },
   "source": [
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BkDCEWWwEzIc",
    "outputId": "3bff1bd3-1779-49d2-d79e-4e334d9f525b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\r\n",
      "is the driest thing I know.\n",
      "\n",
      "---\n",
      "Oh\r\n",
      "my fur and whiskers!\n",
      "\n",
      "---\n",
      "Alice, âit would be of very little use without my shoulders.\n",
      "\n",
      "---\n",
      "The Mouse did not\r\n",
      "answer, so Alice went on eagerly: âThere is such a nice little dog near\r\n",
      "our house I should like to show you!\n",
      "\n",
      "---\n",
      "âI donât even know what a Mock Turtle is.â\r\n",
      "\r\n",
      "âItâs the thing Mock Turtle Soup is made from,â said the Queen.\r\n",
      "\r\n",
      "\n",
      "\n",
      "---\n",
      "And sheâs such a capital one for catching mice you\r\n",
      "canât think!\n",
      "\n",
      "---\n",
      "Soup\r\n",
      "does very well withoutâMaybe itâs always pepper that makes people\r\n",
      "hot-tempered,â she went on, very much pleased at having found out a new\r\n",
      "kind of rule, âand vinegar that makes them sourâand camomile that makes\r\n",
      "them bitterâandâand barley-sugar and such things that make children\r\n",
      "sweet-tempered.\n",
      "\n",
      "---\n",
      "âCome, thereâs half my plan\r\n",
      "done now!\n",
      "\n",
      "---\n",
      "she knows such a\r\n",
      "very little!\n",
      "\n",
      "---\n",
      "âIâve seen a good many little girls in my time, but never\r\n",
      "_one_ with such a neck as that!\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for s in spacy_closest_sent(sents, sentv, n=10):\n",
    "    print(s)\n",
    "    print('\\n---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones(10)\n",
    "b = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VewB5XqkPLdx"
   },
   "source": [
    "## **References**\n",
    "\n",
    "This notebook is inspired by a [tutorial by Allison Parrish](https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Py3 Research",
   "language": "python",
   "name": "py3_research_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
